<!DOCTYPE html>
<html lang="zh-cn">
<head>
<meta charset="utf-8">
<meta name="description" content="欢迎来到 `bxtkezhan`, 一个独立、开放的知识分享小站。">
<meta name="keywords" content="python,神经网络,人工智能,pytorch,tensor,ai,mnist,softmax,cnn">
<meta name="author" content="bxtkezhan@kk">
<meta name="generator" content="Hugo 0.92.2" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="/css/style.css" type="text/css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700" type="text/css">
<link rel="alternate" href="/index.xml" type="application/rss+xml" title="bxtkezhan@kk">
<title>人工神经网络・批量标准化 - bxtkezhan@kk</title>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7VMHQ286BK"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-7VMHQ286BK');
</script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
<script>MathJax = {tex: {inlineMath: [['$', '$']]}, svg: {fontCache: 'global'}};</script>
<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
<script>mermaid.initialize({startOnLoad:true});</script>
<script src="/js/player.js"></script>
</head>
<body>

<header>
  <div class="container clearfix">
    <a class="path" href="http://bxtkezhan.xyz/">[bxtkezhan@kk]</a>
    <span class="caret"># _</span>
    <div class="right">
      
      
        <a class="path" style="color: var(--base0e)"href="/widle/">widle</a>
      
        <a class="path" style="color: var(--base0e)"href="/strut/">strut</a>
      
    </div>
  </div>
</header>

<div class="container">


<main role="main" class="article">
  
<article class="single" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="meta">

    <span class="key">published on</span>
    <span class="val"><time itemprop="datePublished" datetime="2022-10-03">October 03, 2022</time></span>


    <span class="key">in</span>
    <span class="val">

        <a href="/categories/python">Python</a>

    </span>


  </div>
  <h1 class="headline" itemprop="headline">人工神经网络・批量标准化</h1>
  <section class="body" itemprop="articleBody">
    <p><a href="/post/tutorial_001/">返回教程主页</a></p>
<p><a href="/post/067-convolutional-neural-network/">上篇 人工神经网络・卷积神经网络</a></p>
<p>在数据处理中常常使用标准化技术对数据进行处理，一般来说标准化处理有利于提升模型对数据的拟合效果。我们也可以使用标准化技术对神经网络模型进行升级。</p>
<h3 id="批量标准化">批量标准化</h3>
<p>使用批量标准化BatchNormalization方法，我们可以对神经网络模型进行优化。批量标准化的数学公式如下:</p>
<p>$$
y = \frac{x - E[x]}{\sqrt{Var(x) + \epsilon}} \ast \gamma + \beta
$$</p>
<p>公式当中的 $\epsilon$ 通常会是一个非常小的正数，用于防止程序出现除0错误，故此公式可以看成:</p>
<p>$$
y = \frac{x - E[x]}{\sqrt{Var(x)}} \ast \gamma + \beta
$$</p>
<p>即: $x$ 减去 $x$ 的期望 $E[x]$ 然后除以方差 $Var(x)$ 的开根，再乘上参数 $\gamma$ 最后加上参数 $\beta$ 。其中参数 $\gamma , \beta$ 是需要训练更新的值，在PyTorch中，初始情况下 $\gamma$ 的元素值被设置为1而 $\beta$ 的元素值被设置为0。</p>
<h3 id="优化代码">优化代码</h3>
<p>我们对之前的卷积神经网络进行优化，先前的模型结构如下:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">cnn <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
    nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">5</span>),
    nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
    nn<span style="color:#f92672">.</span>MaxPool2d(<span style="color:#ae81ff">2</span>),
    nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">3</span>),
    nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
    nn<span style="color:#f92672">.</span>MaxPool2d(<span style="color:#ae81ff">2</span>),
    nn<span style="color:#f92672">.</span>Flatten(),
    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">20</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">5</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">10</span>),
    nn<span style="color:#f92672">.</span>Softmax(dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))
</code></pre></div><p>经过优化后的结构如下:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">cnn <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
    nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">5</span>),
    nn<span style="color:#f92672">.</span>BatchNorm2d(<span style="color:#ae81ff">10</span>),
    nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
    nn<span style="color:#f92672">.</span>MaxPool2d(<span style="color:#ae81ff">2</span>),
    nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">3</span>),
    nn<span style="color:#f92672">.</span>BatchNorm2d(<span style="color:#ae81ff">20</span>),
    nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
    nn<span style="color:#f92672">.</span>MaxPool2d(<span style="color:#ae81ff">2</span>),
    nn<span style="color:#f92672">.</span>Flatten(),
    nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">20</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">5</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">10</span>),
    nn<span style="color:#f92672">.</span>Softmax(dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))
</code></pre></div><p>我们在卷积层<code>nn.Conv2d</code>后面插入批量标准化层<code>nn.BatchNorm2d</code>来实现数据标准化，需要注意的是批量标准化层的第一个参数应该被指定为卷积层输出的通道数量，例如: <code>nn.Conv2d(1, 10, 5)</code>对应<code>nn.BatchNorm2d(10)</code>；<code>nn.Conv2d(10, 20, 3)</code>对应<code>nn.BatchNorm2d(20)</code>。</p>
<h3 id="重新运行代码训练模型">重新运行代码训练模型</h3>
<p>接下来，我们在同之前一样的条件下重新训练这个卷积神经网络。</p>
<p>通过10轮的训练，我们的新模型在测试集上的表现如下:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">testing<span style="color:#f92672">...</span>
loss<span style="color:#f92672">=</span><span style="color:#ae81ff">1.4737657746182213</span>, accuracy<span style="color:#f92672">=</span><span style="color:#ae81ff">0.9891</span>
</code></pre></div><p>其中损失率<code>loss</code>为1.4737657左右，准确率达到98.91%。</p>
<p>这一次改善在非常大的程度上提高了拟合效率，在训练进行到第二轮的时候测试集准确率就超过了上一代网络的最终测试集准确率，并且在完成10轮训练后，测试集的准确率直逼99%，如果我们增加几轮训练，估计达到99%的测试集准确率不是问题。</p>

  </section>
</article>

</main>

</div>

<footer>
  <div class="container">
    友情分享:
    
    <span><a href="https://wd.bible/">微读圣经</a></span>
    
    <span><a href="https://cnbible.com/">网上圣经</a></span>
    
  </div>
  <div class="container">
    <span class="copyright">&copy; 2022 bxtkezhan@kk - <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></span>
  </div>
</footer>

</body>
</html>

