<!DOCTYPE html>
<html lang="zh-cn">
<head>
<meta charset="utf-8">
<meta name="description" content="**vikit-learn** 是一个基于深度学习技术，使用 Python 开发的计算机视觉处理工具包。">
<meta name="keywords" content="computer,vision,deep,learning,classification,detection,segmentation">
<meta name="author" content="bxtkezhan@kk">
<meta name="generator" content="Hugo 0.121.1">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="/css/style.css" type="text/css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700" type="text/css">
<link rel="alternate" href="/index.xml" type="application/rss+xml" title="bxtkezhan@kk">
<title>vikit-learn 介绍 - bxtkezhan@kk</title>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7VMHQ286BK"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-7VMHQ286BK');
</script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
<script>MathJax = {tex: {inlineMath: [['$', '$']]}, svg: {fontCache: 'global'}};</script>
<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
<script>mermaid.initialize({startOnLoad:true});</script>
<script src="/js/player.js"></script>
</head>
<body>

<header>
  <div class="container clearfix">
    <a class="path" href="http://bxtkezhan.github.io/">[bxtkezhan@kk]</a>
    <span class="caret"># _</span>
    <div class="right">
      
      
        <a class="path" style="color: var(--base0e)"href="/widle/">widle</a>
      
        <a class="path" style="color: var(--base0e)"href="/strut/">strut</a>
      
    </div>
  </div>
</header>

<div class="container">


<main role="main" class="article">
  
<article class="single" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="meta">

    <span class="key">published on</span>
    <span class="val"><time itemprop="datePublished" datetime="2024-08-19">August 19, 2024</time></span>


    <span class="key">in</span>
    <span class="val">

        <a href="/categories/vikit-learn">vikit-learn</a>

    </span>


  </div>
  <h1 class="headline" itemprop="headline">vikit-learn 介绍</h1>
  <section class="body" itemprop="articleBody">
    <p>最近我新开发了一个 Python 工具，给大家介绍一下：<strong>vikit-learn</strong> 是一个基于深度学习技术，使用 Python 开发的计算机视觉处理工具包。该软件包旨在提供一系列易于使用的工具，可以处理现实世界中的任务。该项目仍在积极建设和开发中，敬请期待！</p>
<p><img src="/img/100/intro.png" alt=""></p>
<p><strong>目前支持的功能：</strong> 1. 图像分类; 2. 目标检测; 3. 语义分割; 4. 关键点和关节检测;</p>
<h2 id="vikit-learn-的安装">vikit-learn 的安装</h2>
<h3 id="依赖包">依赖包</h3>
<ul>
<li>matplotlib&gt;=3.7.5</li>
<li>torch&gt;=2.1.2</li>
<li>torchvision&gt;=0.16.2</li>
<li>torchmetrics&gt;=1.4.0</li>
<li>lightning-utilities&gt;=0.11.2</li>
<li>faster-coco-eval&gt;=1.5.4</li>
<li>pycocotools&gt;=2.0.7</li>
<li>clip @ git+https://github.com/openai/CLIP.git</li>
<li>opencv-python&gt;=4.10.0</li>
</ul>
<h3 id="使用-pip-工具进行在线安装">使用 pip 工具进行在线安装</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pip install git+https://github.com/bxt-kk/vikit-learn.git
</span></span></code></pre></div><h2 id="vikit-learn-的使用">vikit-learn 的使用</h2>
<h3 id="训练自己的模型">训练自己的模型</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import `pytorch` and `vklearn`</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.utils.data <span style="color:#f92672">import</span> DataLoader
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> vklearn.trainer.trainer <span style="color:#f92672">import</span> Trainer
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> vklearn.trainer.tasks <span style="color:#f92672">import</span> Detection
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> vklearn.models.trimnetdet <span style="color:#f92672">import</span> TrimNetDet <span style="color:#66d9ef">as</span> Model
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> vklearn.datasets.oxford_iiit_pet <span style="color:#f92672">import</span> OxfordIIITPet
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>dataset_root <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;/kaggle/working/OxfordIIITPet&#39;</span>
</span></span><span style="display:flex;"><span>dataset_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;detection&#39;</span>
</span></span><span style="display:flex;"><span>device       <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#39;cuda&#39;</span> <span style="color:#66d9ef">if</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>is_available() <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#39;cpu&#39;</span>)
</span></span><span style="display:flex;"><span>batch_size   <span style="color:#f92672">=</span> <span style="color:#ae81ff">16</span>
</span></span><span style="display:flex;"><span>lr           <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-3</span>
</span></span><span style="display:flex;"><span>lrf          <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.2</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get default transforms from TRBNetX</span>
</span></span><span style="display:flex;"><span>train_transforms, test_transforms <span style="color:#f92672">=</span> Model<span style="color:#f92672">.</span>get_transforms(<span style="color:#e6db74">&#39;cocox448&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create datasets</span>
</span></span><span style="display:flex;"><span>train_data <span style="color:#f92672">=</span> OxfordIIITPet(
</span></span><span style="display:flex;"><span>    dataset_root,
</span></span><span style="display:flex;"><span>    split<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;trainval&#39;</span>,
</span></span><span style="display:flex;"><span>    target_types<span style="color:#f92672">=</span>dataset_type,
</span></span><span style="display:flex;"><span>    transforms<span style="color:#f92672">=</span>train_transforms)
</span></span><span style="display:flex;"><span>test_data <span style="color:#f92672">=</span> OxfordIIITPet(
</span></span><span style="display:flex;"><span>    dataset_root,
</span></span><span style="display:flex;"><span>    split<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;trainval&#39;</span>,
</span></span><span style="display:flex;"><span>    target_types<span style="color:#f92672">=</span>dataset_type,
</span></span><span style="display:flex;"><span>    transforms<span style="color:#f92672">=</span>test_transforms)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create model TrbnetX</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> Model(
</span></span><span style="display:flex;"><span>    categories<span style="color:#f92672">=</span>train_data<span style="color:#f92672">.</span>bin_classes,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create DataLoader</span>
</span></span><span style="display:flex;"><span>train_loader <span style="color:#f92672">=</span> DataLoader(
</span></span><span style="display:flex;"><span>    train_data, batch_size,
</span></span><span style="display:flex;"><span>    shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    drop_last<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    collate_fn<span style="color:#f92672">=</span>model<span style="color:#f92672">.</span>collate_fn,
</span></span><span style="display:flex;"><span>    num_workers<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>test_loader <span style="color:#f92672">=</span> DataLoader(
</span></span><span style="display:flex;"><span>    test_data, batch_size,
</span></span><span style="display:flex;"><span>    shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>    drop_last<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    collate_fn<span style="color:#f92672">=</span>model<span style="color:#f92672">.</span>collate_fn,
</span></span><span style="display:flex;"><span>    num_workers<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(len(train_loader))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Build object detection task</span>
</span></span><span style="display:flex;"><span>task <span style="color:#f92672">=</span> Detection(
</span></span><span style="display:flex;"><span>    model, device, metric_options<span style="color:#f92672">=</span>{<span style="color:#e6db74">&#39;conf_thresh&#39;</span>: <span style="color:#ae81ff">0.05</span>},
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Build a trainer by specifying the training task and setting up trainer parameters</span>
</span></span><span style="display:flex;"><span>trainer <span style="color:#f92672">=</span> Trainer(
</span></span><span style="display:flex;"><span>    task,
</span></span><span style="display:flex;"><span>    output<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;/kaggle/working/catdog&#39;</span>,
</span></span><span style="display:flex;"><span>    checkpoint<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>    train_loader<span style="color:#f92672">=</span>train_loader,
</span></span><span style="display:flex;"><span>    test_loader<span style="color:#f92672">=</span>test_loader,
</span></span><span style="display:flex;"><span>    epochs<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,
</span></span><span style="display:flex;"><span>    lr<span style="color:#f92672">=</span>lr,
</span></span><span style="display:flex;"><span>    lrf<span style="color:#f92672">=</span>lrf,
</span></span><span style="display:flex;"><span>    show_step<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>,
</span></span><span style="display:flex;"><span>    drop_optim<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    drop_lr_scheduler<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    save_epoch<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize the trainer, then perform training.</span>
</span></span><span style="display:flex;"><span>trainer<span style="color:#f92672">.</span>initialize()
</span></span><span style="display:flex;"><span>trainer<span style="color:#f92672">.</span>fit()
</span></span></code></pre></div><p>训练完成后，将在 <code>/kaggle/working/logs/</code> 目录中生成模型训练结果的可视化图像。</p>
<p><img src="/img/100/CATDOG-LOG-240818-15:22:23_loss.png" alt="">
<img src="/img/100/CATDOG-LOG-240818-15:22:23_conf_f1.png" alt="">
<img src="/img/100/CATDOG-LOG-240818-15:22:23_iou_score.png" alt="">
<img src="/img/100/CATDOG-LOG-240818-15:22:23_map.png" alt="">
<img src="/img/100/CATDOG-LOG-240818-15:22:23_map_50.png" alt=""></p>
<p>我设计的 focal-boost 损失函数，使得模型能够成功地训练于正样本比例极低的任务。</p>
<h2 id="使用训练好的模型">使用训练好的模型</h2>
<p>我们可以通过以下方式调用训练好的目标检测模型：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Import `vklearn`</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> vklearn.models.trimnetdet <span style="color:#f92672">import</span> TrimNetDet <span style="color:#66d9ef">as</span> Model
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> vklearn.pipelines.detector <span style="color:#f92672">import</span> Detector <span style="color:#66d9ef">as</span> Pipeline
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pipeline <span style="color:#f92672">=</span> Pipeline<span style="color:#f92672">.</span>load_from_state(Model, <span style="color:#e6db74">&#39;/kaggle/working/catdog-best.pt&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> PIL <span style="color:#f92672">import</span> Image
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>img <span style="color:#f92672">=</span> Image<span style="color:#f92672">.</span>open(<span style="color:#e6db74">&#39;??YOUR IMAGE PATH??&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Detect and display results</span>
</span></span><span style="display:flex;"><span>objs <span style="color:#f92672">=</span> pipeline(img, align_size<span style="color:#f92672">=</span><span style="color:#ae81ff">448</span>)
</span></span><span style="display:flex;"><span>print(len(objs), objs)
</span></span><span style="display:flex;"><span>fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure()
</span></span><span style="display:flex;"><span>pipeline<span style="color:#f92672">.</span>plot_result(img, objs, fig)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p>这里是一些示例：</p>
<p><img src="/img/100/Figure_01.png" alt="">
<img src="/img/100/Figure_02.png" alt="">
<img src="/img/100/Figure_03.png" alt="">
<img src="/img/100/Figure_04.png" alt="">
<img src="/img/100/Figure_05.png" alt="">
<img src="/img/100/Figure_06.png" alt="">
<img src="/img/100/Figure_07.png" alt="">
<img src="/img/100/Figure_08.png" alt=""></p>
<p>这里是一些关于图像分类的示例：</p>
<p><img src="/img/100/Figure_11.png" alt="">
<img src="/img/100/Figure_12.png" alt="">
<img src="/img/100/Figure_13.png" alt="">
<img src="/img/100/Figure_14.png" alt="">
<img src="/img/100/Figure_15.png" alt="">
<img src="/img/100/Figure_16.png" alt=""></p>
<p>这里是一些关于语义分割的示例：</p>
<p><img src="/img/100/Figure_21.png" alt="">
<img src="/img/100/Figure_22.png" alt="">
<img src="/img/100/Figure_23.png" alt="">
<img src="/img/100/Figure_24.png" alt="">
<img src="/img/100/Figure_25.png" alt="">
<img src="/img/100/Figure_26.png" alt=""></p>
<p>这里是一些支持方向定位的目标检测示例，该项技术基于 关键点与关节 检测技术实现。</p>
<p><img src="/img/100/Figure_31.png" alt="">
<img src="/img/100/Figure_32.png" alt="">
<img src="/img/100/Figure_33.png" alt="">
<img src="/img/100/Figure_34.png" alt=""></p>

  </section>
</article>

</main>

</div>

<footer>
  <div class="container">
    友情分享:
    
    <span><a href="https://wd.bible/">微读圣经</a></span>
    
    <span><a href="https://cnbible.com/">网上圣经</a></span>
    
  </div>
  <div class="container">
    <span class="copyright">&copy; 2024 bxtkezhan@kk - <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></span>
  </div>
</footer>

</body>
</html>

